{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "accepting-avatar",
   "metadata": {},
   "source": [
    "# test implementations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "sweet-mechanics",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "import sklearn as skl\n",
    "from sklearn import preprocessing\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "#Our implementations\n",
    "import kNN as OurKNN\n",
    "import RidgeRegression as OurRidge\n",
    "\n",
    "cross_validator10 = skl.model_selection.StratifiedKFold(n_splits=10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "trained-sentence",
   "metadata": {},
   "source": [
    "#### Dataset 1: Wikipedia maths\n",
    "Json structure:\n",
    "{\"edges\":[[x,y]... array of ordered tuples of links],\n",
    "\"weights\":[(ordered) array of weights for the edges, I guess they represent the number of times one topic is linked to another],\n",
    "\"node_ids\":{\"topic name\": id, set of ids for all topics},\n",
    "\"time_periods\":731,\n",
    "\"0\": {\"index\":0, \"year\":2019, \"month\": 3, \"day\":16, \"y\":[124, 1240, 123...]},\n",
    "\"1\":{\"index\":1, ...}\n",
    "...\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "italic-romania",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.         -1.         -0.63636364  0.06666667 -1.          1.\n",
      "  -1.         -1.         -1.         -1.         -1.         -0.6099423 ]\n",
      " [-0.99725652 -1.         -0.63636364  0.13333333 -1.         -1.\n",
      "   1.         -1.         -1.         -1.         -1.         -0.48520627]\n",
      " [-0.99451303 -1.         -0.63636364  0.2        -1.         -1.\n",
      "  -1.          1.         -1.         -1.         -1.         -0.06257736]\n",
      " [-0.99176955 -1.         -0.63636364  0.26666667 -1.         -1.\n",
      "  -1.         -1.          1.         -1.         -1.         -0.015498  ]\n",
      " [-0.98902606 -1.         -0.63636364  0.33333333 -1.         -1.\n",
      "  -1.         -1.         -1.          1.         -1.         -0.04588221]]\n",
      "[-56775.50958904 151157.49041096 174320.49041096 159371.49041096\n",
      " 130004.49041096]\n"
     ]
    }
   ],
   "source": [
    "# Load data, process, potentially plot some distributions\n",
    "# 731 days * 1068 topics = 780708 instances\n",
    "\n",
    "with open('data/wikivital_mathematics.json') as data_file:    \n",
    "    math_data = json.load(data_file)\n",
    "    \n",
    "keys = math_data.keys()\n",
    "\n",
    "topics_id = math_data[\"node_ids\"]\n",
    "topics = math_data[\"node_ids\"].keys()\n",
    "\n",
    "X = []\n",
    "Y = []\n",
    "\n",
    "prev_total_visitors = 0\n",
    "for day in range(int(math_data['time_periods'])):\n",
    "    day_data = math_data[str(day)]\n",
    "    \n",
    "    index = day_data['index']\n",
    "    year = day_data['year']\n",
    "    month = day_data['month']\n",
    "    date = day_data['day']\n",
    "    weekday = index % 7\n",
    "    \n",
    "    #Calculate the number of visitors this day as target + feature for next day.\n",
    "    total_visitors = 0\n",
    "    for visitors in day_data['y']:\n",
    "        total_visitors = total_visitors + int(visitors)\n",
    "    \n",
    "    #We can't use first day since \n",
    "    if(index>0):\n",
    "        # \n",
    "        x = [index, year, month, date]\n",
    "        \n",
    "        # One hot encode weekday\n",
    "        for i in range(7):\n",
    "            if(i == weekday):\n",
    "                x.append(1)\n",
    "            else:\n",
    "                x.append(0)\n",
    "        \n",
    "        x.append(prev_total_visitors)\n",
    "                  \n",
    "        X.append(x)\n",
    "        Y.append(total_visitors)\n",
    "        \n",
    "    prev_total_visitors = total_visitors\n",
    "\n",
    "X = np.array(X)\n",
    "Y = np.array(Y)\n",
    "\n",
    "#Preprocess features. scale to [-1, 1]\n",
    "scaler = preprocessing.MinMaxScaler(feature_range=(-1,1))\n",
    "scaler.fit(X)\n",
    "X = scaler.transform(X)\n",
    "\n",
    "#Preprocess target. Subtract mean.\n",
    "Y = Y - np.mean(Y)\n",
    "\n",
    "\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pediatric-american",
   "metadata": {},
   "source": [
    "#### Dataset 2: Energy efficiency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "latin-turner",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data, process, potentially plot some distributions\n",
    "\n",
    "df_raw = pd.read_csv('data/energy_efficiency_data.csv')\n",
    "num_entries = df_raw.shape[0]\n",
    "num_attributes = df_raw.shape[1]\n",
    "\n",
    "df_shuffeled = df_raw.sample(frac=1,random_state=193520285)\n",
    "\n",
    "#Preprocess target: Pick one of two possible targets, mean = 0 \n",
    "Y = df_shuffeled.values[:,-2:-1]\n",
    "Y = np.reshape(Y, len(Y))\n",
    "Y = Y - np.mean(Y)\n",
    "\n",
    "#Preprocess features. Scale all to [0,1]\n",
    "X = df_shuffeled.values[:,:-2]\n",
    "scaler = preprocessing.MinMaxScaler(feature_range=(-1,1))\n",
    "scaler.fit(X)\n",
    "X = scaler.transform(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "elect-logic",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ridge regression, own and available implementation + plot\n",
    "\n",
    "learning_rate = 0.00009\n",
    "lambda_parameter = 10.00 \n",
    "max_iterations = 400\n",
    "\n",
    "    \n",
    "# Fit models\n",
    "OurRidge.fit(X,Y, lambda_parameter, learning_rate, max_iter = max_iterations, quiet=False)\n",
    "    \n",
    "#availableRidge = Ridge(lambda_parameter, fit_intercept=False, max_iter=max_iterations)\n",
    "#availableRidge.fit(X[train_index],Y[train_index])\n",
    "    \n",
    "#Test models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "protective-honduras",
   "metadata": {},
   "outputs": [],
   "source": [
    "# kNN \n",
    "\n",
    "OurKNN.fit(X,Y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "noticed-campus",
   "metadata": {},
   "source": [
    "#### Dataset 3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "august-accountability",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded wind power data.\n"
     ]
    }
   ],
   "source": [
    "# Load data, process, potentially plot some distributions\n",
    "\n",
    "features_raw = pd.read_csv('data/wind_power_features.csv')\n",
    "target_raw   = pd.read_csv('data/wind_power_target.csv')\n",
    "num_entries = features_raw.shape[0]\n",
    "num_attributes = features_raw.shape[1]\n",
    "\n",
    "dataset_size = 10000\n",
    "\n",
    "#Preprocess target: Pick one of two possible targets, mean = 0 \n",
    "Y = target_raw.values[:dataset_size,1]\n",
    "Y = Y - np.mean(Y)\n",
    "\n",
    "#Preprocess features. Scale all to [-1,1]. Impute with mean\n",
    "X = features_raw.values[:dataset_size,1:]\n",
    "scaler = preprocessing.MinMaxScaler(feature_range=(-1,1))\n",
    "scaler.fit(X)\n",
    "X = scaler.transform(X)\n",
    "imp = SimpleImputer(missing_values = np.nan, strategy='mean')\n",
    "imp.fit(X)\n",
    "X = imp.transform(X)\n",
    "\n",
    "print(\"Loaded wind power data.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "atlantic-distributor",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ridge regression, own and available implementation + plot\n",
    "\n",
    "learning_rate = 0.0000001\n",
    "lambda_parameter = 100.00 \n",
    "max_iterations = 400\n",
    "\n",
    "#Fit models\n",
    "cv=KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "our_time=[]\n",
    "skl_time=[]\n",
    "\n",
    "pred_df=pd.DataFrame(columns =[0,1,2])\n",
    "\n",
    "for train_index, test_index in cv.split(X):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = Y[train_index], Y[test_index]\n",
    "        \n",
    "    # Fit models\n",
    "    start=time.time()\n",
    "    OurRidge.fit(X_train,y_train, lambda_parameter, learning_rate, max_iter = max_iterations, quiet=False)\n",
    "    our_pred=OurRidge.regress_all(X_test)\n",
    "    our_time.append(time.time()-start)\n",
    "        \n",
    "    start=time.time()\n",
    "    availableRidge = Ridge(lambda_parameter, fit_intercept=False, max_iter=max_iterations)\n",
    "    availableRidge.fit(X_train,y_train)\n",
    "    skl_pred=availableRidge.predict(X_test)\n",
    "    skl_time.append(time.time()-start)\n",
    "        \n",
    "    pred_df=pd.concat([pred_df,pd.DataFrame(list(zip(y_test,our_pred,skl_pred)))],axis=0)\n",
    "    \n",
    "    break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
